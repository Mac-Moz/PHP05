# ①課題番号-プロダクト名

スクレイピングアプリ(ver02_AIサマリ機能付)

## ②課題内容（どんな作品か）
<ver02追加機能>
-AIによる記事のサマリ機能(ユーザー区分により表示を制御)
-home画面の出力を最新記事から表示
-重複記事をDBから削除
-ログイン機能

<ver01機能>
-scrapyを利用したWebサイトからスクレイピングしたデータをDBに登録
--python scrapyにより特定のサイトからNewsデータを取得するコードを作成
--Scrapy Cloud(https://www.zyte.com/scrapy-cloud/)にデプロイしてスクレイピングを実行
--Scrapy CloudよりAPIにより取得したデータを読み込みDBへ登録
-RSSフィードから情報を取得したデータをDBに登録
- DBに登録した情報を表示する

（フォルダ：”Luup”にpythonのコードは格納しました）
## ③DEMO

[デプロイしている場合はURLを記入（任意）](http://chandori-pork.sakura.ne.jp/kadai03/index.php)

## ④作ったアプリケーション用のIDまたはPasswordがある場合

- ID: test1
- PW: test1

## ⑤工夫した点・こだわった点

- python(scrapy)によるスクレイピングを習得できるように時間を費やした
- スクレイピングデータをサーバーにどのように渡すかを検討しAPIで取得できる仕組みを構築した
-RSSフィードを取得できる仕組みを構築した

## ⑥難しかった点・次回トライしたいこと(又は機能)
難しかった点
- python(scrapy)の環境構築
- spider実行によるXPATHの記述方法
- APIから取得したデータをJson形式に変換するのに、カンマを追加するなどの処理が必要であった（いまだにこの処理が必要なのか不明）
- 取得したデータをDBのカラムに格納する処理
次回トライする点
- DB側の処理（重複データの削除、表示順序の変更）
- スクレイピング処理の簡略化、パッケージ化
- 定期的なスクレイピング処理の実行方法（現状はScrapy Cloudで可能だが、できればサーバーにて実行したい）
-　スクレイピング、RSSの新規プロジェクトの作成処理

## ⑦質問・疑問・感想、シェアしたいこと等なんでも

- [質問]
APIのデータがJson形式で読み込めない問題を解決したい
- [感想]
冬休みほどんと費やしました。何とかここまで形にできてよかった
- [参考記事]
  - 1. [URLをここに記入]

  - 2. [URLをここに記入]
